{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"# Import packages\n\nimport tensorflow as tf\nimport numpy as np\nimport os\nimport random\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import RobustScaler\nimport warnings\nimport logging\n\ntfk = tf.keras\ntfkl = tf.keras.layers\nprint(tf.__version__)","metadata":{"id":"Z_wVYNVVfr6q","execution":{"iopub.status.busy":"2022-12-15T21:10:17.137859Z","iopub.execute_input":"2022-12-15T21:10:17.138253Z","iopub.status.idle":"2022-12-15T21:10:18.204673Z","shell.execute_reply.started":"2022-12-15T21:10:17.138217Z","shell.execute_reply":"2022-12-15T21:10:18.202785Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"2.6.4\n","output_type":"stream"}]},{"cell_type":"code","source":"# Random seed for reproducibility\n\nseed = 69\n\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)","metadata":{"id":"imBtfhUPLwB-","execution":{"iopub.status.busy":"2022-12-15T21:10:20.518179Z","iopub.execute_input":"2022-12-15T21:10:20.518637Z","iopub.status.idle":"2022-12-15T21:10:20.531627Z","shell.execute_reply.started":"2022-12-15T21:10:20.518596Z","shell.execute_reply":"2022-12-15T21:10:20.529799Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Remove warnings\n\nimport warnings\nimport logging\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=Warning)\ntf.get_logger().setLevel('INFO')\ntf.autograph.set_verbosity(0)\n\ntf.get_logger().setLevel(logging.ERROR)\ntf.get_logger().setLevel('ERROR')\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T21:10:22.926412Z","iopub.execute_input":"2022-12-15T21:10:22.926766Z","iopub.status.idle":"2022-12-15T21:10:22.933895Z","shell.execute_reply.started":"2022-12-15T21:10:22.926735Z","shell.execute_reply":"2022-12-15T21:10:22.932842Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading and Preprocessing","metadata":{}},{"cell_type":"code","source":"# Loading x\n\nx = np.load(\"/kaggle/input/training-dataset-homework-2/x_train.npy\")\nprint(x.shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T21:10:26.077059Z","iopub.execute_input":"2022-12-15T21:10:26.077640Z","iopub.status.idle":"2022-12-15T21:10:26.172529Z","shell.execute_reply.started":"2022-12-15T21:10:26.077605Z","shell.execute_reply":"2022-12-15T21:10:26.171449Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(2429, 36, 6)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Loading y\n\ny = np.load(\"/kaggle/input/training-dataset-homework-2/y_train.npy\")\nprint(y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T21:10:28.560933Z","iopub.execute_input":"2022-12-15T21:10:28.561628Z","iopub.status.idle":"2022-12-15T21:10:28.572715Z","shell.execute_reply.started":"2022-12-15T21:10:28.561591Z","shell.execute_reply":"2022-12-15T21:10:28.571457Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(2429,)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define useful constants\n\nOUTPUT_SHAPE = 12\nFEATURE_NUMBER = 6\nTIME_INTERVAL = 36","metadata":{"execution":{"iopub.status.busy":"2022-12-15T21:10:31.096657Z","iopub.execute_input":"2022-12-15T21:10:31.097007Z","iopub.status.idle":"2022-12-15T21:10:31.101597Z","shell.execute_reply.started":"2022-12-15T21:10:31.096974Z","shell.execute_reply":"2022-12-15T21:10:31.100646Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Data splitting function into training and validation sets\n\ndef split_data(data, labels, train_percentage):\n    \n    y_count = np.zeros(OUTPUT_SHAPE,dtype=int)\n    x_train = np.empty(shape=(0,36,6))\n    x_val = np.empty(shape=(0,36,6))\n    y_train = np.empty(shape=(0), dtype=int)\n    y_val = np.empty(shape=(0), dtype=int)\n    \n    for l in labels:\n        y_count[l] += 1\n    \n    for l in range(OUTPUT_SHAPE):\n        n_train = (int)(y_count[l]*train_percentage)\n        x_train = np.append(x_train, data[labels == l][:n_train, :, :], axis=0)\n        y_train = np.append(y_train, labels[labels == l][:n_train])\n        x_val = np.append(x_val, data[labels == l][n_train:, :, :], axis=0)\n        y_val = np.append(y_val, labels[labels == l][n_train:])\n        \n    return x_train, x_val, y_train, y_val","metadata":{"execution":{"iopub.status.busy":"2022-12-15T21:10:36.217963Z","iopub.execute_input":"2022-12-15T21:10:36.218664Z","iopub.status.idle":"2022-12-15T21:10:36.227138Z","shell.execute_reply.started":"2022-12-15T21:10:36.218627Z","shell.execute_reply":"2022-12-15T21:10:36.225982Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Data splitting into training set and validation set\n\nx_train, x_val, y_train, y_val = split_data(x, y, 0.85)\n\nprint(x_train.shape, y_train.shape, x_val.shape, y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T21:10:39.346779Z","iopub.execute_input":"2022-12-15T21:10:39.347234Z","iopub.status.idle":"2022-12-15T21:10:39.370870Z","shell.execute_reply.started":"2022-12-15T21:10:39.347196Z","shell.execute_reply":"2022-12-15T21:10:39.370028Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"(2059, 36, 6) (2059,) (370, 36, 6) (370,)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Normalization function to normalize the data\n\ndef normalization_easier(data, val_data):\n    x_train_pre = data.copy()\n    x_val_pre = val_data.copy()\n    scaler = RobustScaler()\n    \n    x_train_pre = scaler.fit_transform(data.reshape(-1, data.shape[-1])).reshape(data.shape)      \n    x_val_pre = scaler.transform(val_data.reshape(-1, val_data.shape[-1])).reshape(val_data.shape)\n    return x_train_pre, x_val_pre","metadata":{"execution":{"iopub.status.busy":"2022-12-15T21:10:50.237653Z","iopub.execute_input":"2022-12-15T21:10:50.238000Z","iopub.status.idle":"2022-12-15T21:10:50.244498Z","shell.execute_reply.started":"2022-12-15T21:10:50.237970Z","shell.execute_reply":"2022-12-15T21:10:50.243453Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Normalize the data\n\na, b = normalization_easier(x_train,x_val)\na.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-15T21:10:53.366611Z","iopub.execute_input":"2022-12-15T21:10:53.367062Z","iopub.status.idle":"2022-12-15T21:10:53.448944Z","shell.execute_reply.started":"2022-12-15T21:10:53.367005Z","shell.execute_reply":"2022-12-15T21:10:53.447977Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(2059, 36, 6)"},"metadata":{}}]},{"cell_type":"code","source":"# Define a function to save into a file the useful parameters to perform normalization\n\nfrom pickle import dump\ndef get_parameters_normalization(data, val_data):\n    x_train_pre = data.copy()\n    x_val_pre = val_data.copy()\n    scaler = RobustScaler()\n    scaler = scaler.fit(data.reshape(-1, data.shape[-1]))\n    dump(scaler, open('scaler_15_12_second_model.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2022-12-15T21:32:42.947385Z","iopub.execute_input":"2022-12-15T21:32:42.947747Z","iopub.status.idle":"2022-12-15T21:32:42.955193Z","shell.execute_reply.started":"2022-12-15T21:32:42.947716Z","shell.execute_reply":"2022-12-15T21:32:42.952930Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Call the previous function to generate the pickle file, to be used in submission (test) phase\n\nget_parameters_normalization(x_train, x_val)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T21:32:45.078600Z","iopub.execute_input":"2022-12-15T21:32:45.078990Z","iopub.status.idle":"2022-12-15T21:32:45.105830Z","shell.execute_reply.started":"2022-12-15T21:32:45.078958Z","shell.execute_reply":"2022-12-15T21:32:45.104691Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"g_0wmrz3MGsd"}},{"cell_type":"code","source":"# Define the input shape, the batch size and the number of epochs\n\ninput_shape = a.shape[1:]\nbatch_size = 32\nepochs = 1000","metadata":{"id":"XkUqhy__KMnr","execution":{"iopub.status.busy":"2022-12-15T21:10:58.817612Z","iopub.execute_input":"2022-12-15T21:10:58.818037Z","iopub.status.idle":"2022-12-15T21:10:58.823537Z","shell.execute_reply.started":"2022-12-15T21:10:58.817996Z","shell.execute_reply":"2022-12-15T21:10:58.822403Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def build_1DCNN_classifier(input_shape, classes):\n    # Build the neural network layer by layer\n    input_layer = tfkl.Input(shape=input_shape, name='Input')\n\n    # Feature extractor\n    cnn = tfkl.Conv1D(filters=128,kernel_size=3,padding='same',activation='relu')(input_layer)\n    d1 = tfkl.Dropout(.2, seed=seed)(cnn)\n    cnn = tfkl.Conv1D(filters=128,kernel_size=3,padding='same',activation='relu')(d1)\n    d2 = tfkl.Dropout(.2, seed=seed)(cnn)\n    cnn = tfkl.Conv1D(filters=128,kernel_size=3,padding='same',activation='relu')(d2)\n    d3 = tfkl.Dropout(.2, seed=seed)(cnn)\n    gap = tfkl.GlobalAveragePooling1D()(d3)\n    dropout = tfkl.Dropout(.5, seed=seed)(gap)\n\n    # Classifier\n    classifier = tfkl.Dense(512, activation='relu')(dropout)\n    dropout2 = tfkl.Dropout(.5, seed=seed)(classifier)\n    classifier2 = tfkl.Dense(64, activation='relu')(dropout2)\n    output_layer = tfkl.Dense(classes, activation='softmax')(classifier2)\n\n    # Connect input and output through the Model class\n    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n\n    # Compile the model\n    model.compile(loss=tfk.losses.SparseCategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n\n    # Return the model\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-12-15T21:29:58.559204Z","iopub.execute_input":"2022-12-15T21:29:58.559567Z","iopub.status.idle":"2022-12-15T21:29:58.571525Z","shell.execute_reply.started":"2022-12-15T21:29:58.559537Z","shell.execute_reply":"2022-12-15T21:29:58.570547Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Get the summary of the built model\n\nmodel = build_1DCNN_classifier(input_shape, OUTPUT_SHAPE)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-15T21:30:03.716447Z","iopub.execute_input":"2022-12-15T21:30:03.716803Z","iopub.status.idle":"2022-12-15T21:30:03.791282Z","shell.execute_reply.started":"2022-12-15T21:30:03.716773Z","shell.execute_reply":"2022-12-15T21:30:03.790213Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nInput (InputLayer)           [(None, 36, 6)]           0         \n_________________________________________________________________\nconv1d_9 (Conv1D)            (None, 36, 128)           2432      \n_________________________________________________________________\ndropout_15 (Dropout)         (None, 36, 128)           0         \n_________________________________________________________________\nconv1d_10 (Conv1D)           (None, 36, 128)           49280     \n_________________________________________________________________\ndropout_16 (Dropout)         (None, 36, 128)           0         \n_________________________________________________________________\nconv1d_11 (Conv1D)           (None, 36, 128)           49280     \n_________________________________________________________________\ndropout_17 (Dropout)         (None, 36, 128)           0         \n_________________________________________________________________\nglobal_average_pooling1d_3 ( (None, 128)               0         \n_________________________________________________________________\ndropout_18 (Dropout)         (None, 128)               0         \n_________________________________________________________________\ndense_9 (Dense)              (None, 512)               66048     \n_________________________________________________________________\ndropout_19 (Dropout)         (None, 512)               0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 64)                32832     \n_________________________________________________________________\ndense_11 (Dense)             (None, 12)                780       \n=================================================================\nTotal params: 200,652\nTrainable params: 200,652\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fit the model\n\nhistory = model.fit(\n    x = a,\n    y = y_train,\n    batch_size = batch_size,\n    epochs = epochs,\n    validation_data=(b, y_val),\n    class_weight = {0: 1,\n                    1: 1,\n                    2: 1,\n                    3: 1,\n                    4: 3,\n                    5: 1,\n                    6: 1,\n                    7: 2,\n                    8: 1,\n                    9: 1,\n                    10: 1,\n                    11: 2},\n    callbacks = [\n        tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=30, restore_best_weights=True),\n        tfk.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=10, factor=0.5, min_lr=1e-5)\n    ]\n).history","metadata":{"execution":{"iopub.status.busy":"2022-12-15T21:30:06.837371Z","iopub.execute_input":"2022-12-15T21:30:06.837745Z","iopub.status.idle":"2022-12-15T21:30:57.998432Z","shell.execute_reply.started":"2022-12-15T21:30:06.837713Z","shell.execute_reply":"2022-12-15T21:30:57.997435Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Epoch 1/1000\n65/65 [==============================] - 1s 6ms/step - loss: 3.1003 - accuracy: 0.2807 - val_loss: 2.3169 - val_accuracy: 0.3459\nEpoch 2/1000\n65/65 [==============================] - 0s 4ms/step - loss: 2.4682 - accuracy: 0.3570 - val_loss: 2.0473 - val_accuracy: 0.3676\nEpoch 3/1000\n65/65 [==============================] - 1s 8ms/step - loss: 2.2838 - accuracy: 0.3667 - val_loss: 1.8819 - val_accuracy: 0.4027\nEpoch 4/1000\n65/65 [==============================] - 0s 5ms/step - loss: 2.1891 - accuracy: 0.3798 - val_loss: 1.9010 - val_accuracy: 0.4135\nEpoch 5/1000\n65/65 [==============================] - 0s 4ms/step - loss: 2.1722 - accuracy: 0.3978 - val_loss: 1.8287 - val_accuracy: 0.4297\nEpoch 6/1000\n65/65 [==============================] - 0s 4ms/step - loss: 2.1448 - accuracy: 0.4235 - val_loss: 1.7621 - val_accuracy: 0.4514\nEpoch 7/1000\n65/65 [==============================] - 0s 4ms/step - loss: 2.0656 - accuracy: 0.4264 - val_loss: 1.6526 - val_accuracy: 0.4703\nEpoch 8/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.9994 - accuracy: 0.4449 - val_loss: 1.7376 - val_accuracy: 0.4486\nEpoch 9/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.9899 - accuracy: 0.4512 - val_loss: 1.5752 - val_accuracy: 0.4784\nEpoch 10/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.8237 - accuracy: 0.4905 - val_loss: 1.6177 - val_accuracy: 0.5027\nEpoch 11/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.8002 - accuracy: 0.5027 - val_loss: 1.6083 - val_accuracy: 0.5081\nEpoch 12/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.7793 - accuracy: 0.4900 - val_loss: 1.3730 - val_accuracy: 0.5568\nEpoch 13/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.6948 - accuracy: 0.5245 - val_loss: 1.3797 - val_accuracy: 0.5784\nEpoch 14/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.6165 - accuracy: 0.5503 - val_loss: 1.7819 - val_accuracy: 0.5973\nEpoch 15/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.6633 - accuracy: 0.5474 - val_loss: 1.3265 - val_accuracy: 0.5811\nEpoch 16/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.6288 - accuracy: 0.5634 - val_loss: 1.3207 - val_accuracy: 0.5838\nEpoch 17/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.5897 - accuracy: 0.5619 - val_loss: 1.1728 - val_accuracy: 0.5946\nEpoch 18/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.5658 - accuracy: 0.5721 - val_loss: 1.4002 - val_accuracy: 0.5757\nEpoch 19/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.5355 - accuracy: 0.5755 - val_loss: 1.2167 - val_accuracy: 0.6162\nEpoch 20/1000\n65/65 [==============================] - 0s 5ms/step - loss: 1.5305 - accuracy: 0.5663 - val_loss: 1.4034 - val_accuracy: 0.5405\nEpoch 21/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.5430 - accuracy: 0.5750 - val_loss: 1.2397 - val_accuracy: 0.6216\nEpoch 22/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.4426 - accuracy: 0.6017 - val_loss: 1.2012 - val_accuracy: 0.6351\nEpoch 23/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.4075 - accuracy: 0.6187 - val_loss: 1.2114 - val_accuracy: 0.6243\nEpoch 24/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.4069 - accuracy: 0.6246 - val_loss: 1.0915 - val_accuracy: 0.6405\nEpoch 25/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.3711 - accuracy: 0.6285 - val_loss: 1.1465 - val_accuracy: 0.6378\nEpoch 26/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.4351 - accuracy: 0.6129 - val_loss: 1.1684 - val_accuracy: 0.6324\nEpoch 27/1000\n65/65 [==============================] - 0s 5ms/step - loss: 1.3700 - accuracy: 0.6212 - val_loss: 1.2514 - val_accuracy: 0.6243\nEpoch 28/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.3951 - accuracy: 0.6231 - val_loss: 1.1660 - val_accuracy: 0.6243\nEpoch 29/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.3118 - accuracy: 0.6450 - val_loss: 1.1465 - val_accuracy: 0.6459\nEpoch 30/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.3499 - accuracy: 0.6372 - val_loss: 1.1961 - val_accuracy: 0.6405\nEpoch 31/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.3152 - accuracy: 0.6270 - val_loss: 1.0406 - val_accuracy: 0.6297\nEpoch 32/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.2943 - accuracy: 0.6416 - val_loss: 1.0728 - val_accuracy: 0.6622\nEpoch 33/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.2677 - accuracy: 0.6450 - val_loss: 1.0441 - val_accuracy: 0.6676\nEpoch 34/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.2758 - accuracy: 0.6421 - val_loss: 1.0286 - val_accuracy: 0.6622\nEpoch 35/1000\n65/65 [==============================] - 0s 5ms/step - loss: 1.2713 - accuracy: 0.6566 - val_loss: 1.0901 - val_accuracy: 0.6324\nEpoch 36/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.2537 - accuracy: 0.6445 - val_loss: 0.9766 - val_accuracy: 0.6730\nEpoch 37/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.2213 - accuracy: 0.6527 - val_loss: 1.0934 - val_accuracy: 0.6378\nEpoch 38/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.3282 - accuracy: 0.6416 - val_loss: 1.0190 - val_accuracy: 0.6622\nEpoch 39/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.2041 - accuracy: 0.6678 - val_loss: 0.9865 - val_accuracy: 0.6730\nEpoch 40/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.2309 - accuracy: 0.6629 - val_loss: 1.1257 - val_accuracy: 0.6216\nEpoch 41/1000\n65/65 [==============================] - 0s 7ms/step - loss: 1.3474 - accuracy: 0.6411 - val_loss: 1.1033 - val_accuracy: 0.6514\nEpoch 42/1000\n65/65 [==============================] - 0s 6ms/step - loss: 1.2153 - accuracy: 0.6668 - val_loss: 1.0563 - val_accuracy: 0.6649\nEpoch 43/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.2084 - accuracy: 0.6693 - val_loss: 1.1484 - val_accuracy: 0.6649\nEpoch 44/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.1090 - accuracy: 0.6911 - val_loss: 1.1574 - val_accuracy: 0.6703\nEpoch 45/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.1217 - accuracy: 0.6887 - val_loss: 1.0997 - val_accuracy: 0.6784\nEpoch 46/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.0821 - accuracy: 0.7008 - val_loss: 0.9930 - val_accuracy: 0.6838\nEpoch 47/1000\n65/65 [==============================] - 0s 6ms/step - loss: 1.1086 - accuracy: 0.6877 - val_loss: 1.0855 - val_accuracy: 0.6757\nEpoch 48/1000\n65/65 [==============================] - 0s 7ms/step - loss: 1.1821 - accuracy: 0.6693 - val_loss: 1.3234 - val_accuracy: 0.6784\nEpoch 49/1000\n65/65 [==============================] - 0s 6ms/step - loss: 1.2032 - accuracy: 0.6872 - val_loss: 1.1101 - val_accuracy: 0.6459\nEpoch 50/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.1403 - accuracy: 0.6824 - val_loss: 0.9359 - val_accuracy: 0.6946\nEpoch 51/1000\n65/65 [==============================] - 0s 5ms/step - loss: 1.0844 - accuracy: 0.7033 - val_loss: 1.1050 - val_accuracy: 0.7000\nEpoch 52/1000\n65/65 [==============================] - 0s 5ms/step - loss: 1.0691 - accuracy: 0.6969 - val_loss: 1.0643 - val_accuracy: 0.6649\nEpoch 53/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.9923 - accuracy: 0.7159 - val_loss: 1.3417 - val_accuracy: 0.6919\nEpoch 54/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.0910 - accuracy: 0.7071 - val_loss: 1.2206 - val_accuracy: 0.6784\nEpoch 55/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.2565 - accuracy: 0.6717 - val_loss: 1.0826 - val_accuracy: 0.6757\nEpoch 56/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.1215 - accuracy: 0.6853 - val_loss: 1.0668 - val_accuracy: 0.6595\nEpoch 57/1000\n65/65 [==============================] - 0s 4ms/step - loss: 1.0460 - accuracy: 0.7067 - val_loss: 1.0519 - val_accuracy: 0.7108\nEpoch 58/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.9839 - accuracy: 0.7256 - val_loss: 0.9815 - val_accuracy: 0.6811\nEpoch 59/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.9678 - accuracy: 0.7241 - val_loss: 0.9833 - val_accuracy: 0.7162\nEpoch 60/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.9861 - accuracy: 0.7091 - val_loss: 1.1414 - val_accuracy: 0.6919\nEpoch 61/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.9355 - accuracy: 0.7324 - val_loss: 1.4021 - val_accuracy: 0.7135\nEpoch 62/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.9665 - accuracy: 0.7256 - val_loss: 1.1981 - val_accuracy: 0.6973\nEpoch 63/1000\n65/65 [==============================] - 0s 5ms/step - loss: 0.9558 - accuracy: 0.7377 - val_loss: 1.0550 - val_accuracy: 0.6973\nEpoch 64/1000\n65/65 [==============================] - 0s 5ms/step - loss: 0.9541 - accuracy: 0.7329 - val_loss: 1.0885 - val_accuracy: 0.6784\nEpoch 65/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.9433 - accuracy: 0.7368 - val_loss: 0.9882 - val_accuracy: 0.7000\nEpoch 66/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.8910 - accuracy: 0.7460 - val_loss: 1.0963 - val_accuracy: 0.7162\nEpoch 67/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.8663 - accuracy: 0.7460 - val_loss: 1.0500 - val_accuracy: 0.6865\nEpoch 68/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.8440 - accuracy: 0.7669 - val_loss: 1.0304 - val_accuracy: 0.7135\nEpoch 69/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.8466 - accuracy: 0.7606 - val_loss: 1.1329 - val_accuracy: 0.6973\nEpoch 70/1000\n65/65 [==============================] - 0s 5ms/step - loss: 0.9122 - accuracy: 0.7300 - val_loss: 0.9453 - val_accuracy: 0.7243\nEpoch 71/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.7828 - accuracy: 0.7746 - val_loss: 0.9442 - val_accuracy: 0.7162\nEpoch 72/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.7902 - accuracy: 0.7674 - val_loss: 0.9861 - val_accuracy: 0.7135\nEpoch 73/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.7952 - accuracy: 0.7630 - val_loss: 0.9641 - val_accuracy: 0.7270\nEpoch 74/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.7903 - accuracy: 0.7722 - val_loss: 1.1191 - val_accuracy: 0.7270\nEpoch 75/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.7860 - accuracy: 0.7712 - val_loss: 1.0585 - val_accuracy: 0.7162\nEpoch 76/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.7765 - accuracy: 0.7640 - val_loss: 1.1799 - val_accuracy: 0.7081\nEpoch 77/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.7793 - accuracy: 0.7795 - val_loss: 0.9792 - val_accuracy: 0.7162\nEpoch 78/1000\n65/65 [==============================] - 0s 7ms/step - loss: 0.7110 - accuracy: 0.7834 - val_loss: 1.0776 - val_accuracy: 0.7270\nEpoch 79/1000\n65/65 [==============================] - 0s 5ms/step - loss: 0.7376 - accuracy: 0.7824 - val_loss: 0.9893 - val_accuracy: 0.7162\nEpoch 80/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.7282 - accuracy: 0.7858 - val_loss: 1.0278 - val_accuracy: 0.7081\nEpoch 81/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.7150 - accuracy: 0.7897 - val_loss: 0.9990 - val_accuracy: 0.7243\nEpoch 82/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.7198 - accuracy: 0.7771 - val_loss: 1.0448 - val_accuracy: 0.7297\nEpoch 83/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.7989 - val_loss: 1.0106 - val_accuracy: 0.7162\nEpoch 84/1000\n65/65 [==============================] - 0s 5ms/step - loss: 0.7127 - accuracy: 0.7848 - val_loss: 0.9553 - val_accuracy: 0.7405\nEpoch 85/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.7227 - accuracy: 0.7863 - val_loss: 0.9457 - val_accuracy: 0.7324\nEpoch 86/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.7984 - val_loss: 0.9680 - val_accuracy: 0.7324\nEpoch 87/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.6737 - accuracy: 0.7897 - val_loss: 1.0177 - val_accuracy: 0.7324\nEpoch 88/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.6735 - accuracy: 0.7931 - val_loss: 1.0540 - val_accuracy: 0.7081\nEpoch 89/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.7054 - accuracy: 0.7844 - val_loss: 0.9679 - val_accuracy: 0.7135\nEpoch 90/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.6551 - accuracy: 0.8018 - val_loss: 0.9358 - val_accuracy: 0.7243\nEpoch 91/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.8082 - val_loss: 1.0106 - val_accuracy: 0.7243\nEpoch 92/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.6794 - accuracy: 0.7989 - val_loss: 1.1283 - val_accuracy: 0.7000\nEpoch 93/1000\n65/65 [==============================] - 0s 5ms/step - loss: 0.6604 - accuracy: 0.8111 - val_loss: 1.0448 - val_accuracy: 0.7216\nEpoch 94/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.6953 - accuracy: 0.7916 - val_loss: 0.9896 - val_accuracy: 0.7108\nEpoch 95/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.8072 - val_loss: 0.9387 - val_accuracy: 0.7270\nEpoch 96/1000\n65/65 [==============================] - 0s 5ms/step - loss: 0.6134 - accuracy: 0.8130 - val_loss: 1.0130 - val_accuracy: 0.7351\nEpoch 97/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5875 - accuracy: 0.8295 - val_loss: 0.9784 - val_accuracy: 0.7378\nEpoch 98/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.8169 - val_loss: 0.9832 - val_accuracy: 0.7270\nEpoch 99/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5928 - accuracy: 0.8174 - val_loss: 0.9951 - val_accuracy: 0.7297\nEpoch 100/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.8315 - val_loss: 1.0060 - val_accuracy: 0.7351\nEpoch 101/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5959 - accuracy: 0.8261 - val_loss: 1.0287 - val_accuracy: 0.7351\nEpoch 102/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.8130 - val_loss: 0.9446 - val_accuracy: 0.7270\nEpoch 103/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5563 - accuracy: 0.8329 - val_loss: 1.0111 - val_accuracy: 0.7297\nEpoch 104/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.6015 - accuracy: 0.8256 - val_loss: 1.0382 - val_accuracy: 0.7270\nEpoch 105/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5580 - accuracy: 0.8232 - val_loss: 1.0381 - val_accuracy: 0.7351\nEpoch 106/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5623 - accuracy: 0.8213 - val_loss: 1.0439 - val_accuracy: 0.7297\nEpoch 107/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5686 - accuracy: 0.8276 - val_loss: 1.0615 - val_accuracy: 0.7351\nEpoch 108/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5829 - accuracy: 0.8276 - val_loss: 1.0531 - val_accuracy: 0.7297\nEpoch 109/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5787 - accuracy: 0.8203 - val_loss: 1.0161 - val_accuracy: 0.7432\nEpoch 110/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5420 - accuracy: 0.8266 - val_loss: 1.0137 - val_accuracy: 0.7459\nEpoch 111/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.8227 - val_loss: 1.0335 - val_accuracy: 0.7297\nEpoch 112/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5249 - accuracy: 0.8412 - val_loss: 0.9962 - val_accuracy: 0.7324\nEpoch 113/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.8397 - val_loss: 1.0069 - val_accuracy: 0.7270\nEpoch 114/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.8383 - val_loss: 1.0182 - val_accuracy: 0.7405\nEpoch 115/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.8407 - val_loss: 1.0198 - val_accuracy: 0.7405\nEpoch 116/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5529 - accuracy: 0.8392 - val_loss: 1.0155 - val_accuracy: 0.7405\nEpoch 117/1000\n65/65 [==============================] - 0s 7ms/step - loss: 0.5295 - accuracy: 0.8422 - val_loss: 1.0269 - val_accuracy: 0.7351\nEpoch 118/1000\n65/65 [==============================] - 0s 5ms/step - loss: 0.5352 - accuracy: 0.8320 - val_loss: 1.0190 - val_accuracy: 0.7351\nEpoch 119/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.8412 - val_loss: 1.0195 - val_accuracy: 0.7432\nEpoch 120/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.8373 - val_loss: 0.9973 - val_accuracy: 0.7514\nEpoch 121/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.8407 - val_loss: 1.0618 - val_accuracy: 0.7324\nEpoch 122/1000\n65/65 [==============================] - 0s 5ms/step - loss: 0.5118 - accuracy: 0.8378 - val_loss: 1.0539 - val_accuracy: 0.7351\nEpoch 123/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.8334 - val_loss: 1.0417 - val_accuracy: 0.7324\nEpoch 124/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.8397 - val_loss: 1.0104 - val_accuracy: 0.7243\nEpoch 125/1000\n65/65 [==============================] - 0s 5ms/step - loss: 0.5146 - accuracy: 0.8417 - val_loss: 1.0287 - val_accuracy: 0.7351\nEpoch 126/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.8407 - val_loss: 0.9970 - val_accuracy: 0.7405\nEpoch 127/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.8485 - val_loss: 1.0119 - val_accuracy: 0.7432\nEpoch 128/1000\n65/65 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.8538 - val_loss: 1.0045 - val_accuracy: 0.7351\nEpoch 129/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.8475 - val_loss: 0.9832 - val_accuracy: 0.7459\nEpoch 130/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.8441 - val_loss: 0.9936 - val_accuracy: 0.7351\nEpoch 131/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.8480 - val_loss: 1.0307 - val_accuracy: 0.7432\nEpoch 132/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.8490 - val_loss: 1.0240 - val_accuracy: 0.7432\nEpoch 133/1000\n65/65 [==============================] - 0s 5ms/step - loss: 0.4917 - accuracy: 0.8543 - val_loss: 1.0189 - val_accuracy: 0.7378\nEpoch 134/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.8514 - val_loss: 1.0162 - val_accuracy: 0.7297\nEpoch 135/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.8582 - val_loss: 1.0050 - val_accuracy: 0.7351\nEpoch 136/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.8587 - val_loss: 1.0229 - val_accuracy: 0.7378\nEpoch 137/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.8426 - val_loss: 1.0116 - val_accuracy: 0.7514\nEpoch 138/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.8494 - val_loss: 1.0147 - val_accuracy: 0.7459\nEpoch 139/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.8397 - val_loss: 1.0271 - val_accuracy: 0.7514\nEpoch 140/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.8475 - val_loss: 1.0055 - val_accuracy: 0.7324\nEpoch 141/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.8417 - val_loss: 0.9969 - val_accuracy: 0.7459\nEpoch 142/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.8485 - val_loss: 0.9980 - val_accuracy: 0.7541\nEpoch 143/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.8422 - val_loss: 0.9900 - val_accuracy: 0.7568\nEpoch 144/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.8558 - val_loss: 0.9954 - val_accuracy: 0.7514\nEpoch 145/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.8475 - val_loss: 0.9957 - val_accuracy: 0.7541\nEpoch 146/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.8533 - val_loss: 0.9985 - val_accuracy: 0.7486\nEpoch 147/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.8451 - val_loss: 1.0016 - val_accuracy: 0.7486\nEpoch 148/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.8592 - val_loss: 1.0199 - val_accuracy: 0.7459\nEpoch 149/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.8485 - val_loss: 1.0143 - val_accuracy: 0.7486\nEpoch 150/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.8470 - val_loss: 1.0351 - val_accuracy: 0.7541\nEpoch 151/1000\n65/65 [==============================] - 0s 5ms/step - loss: 0.4928 - accuracy: 0.8431 - val_loss: 1.0405 - val_accuracy: 0.7432\nEpoch 152/1000\n65/65 [==============================] - 0s 5ms/step - loss: 0.4959 - accuracy: 0.8397 - val_loss: 1.0378 - val_accuracy: 0.7459\nEpoch 153/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.8470 - val_loss: 1.0317 - val_accuracy: 0.7432\nEpoch 154/1000\n65/65 [==============================] - 0s 5ms/step - loss: 0.4972 - accuracy: 0.8422 - val_loss: 1.0372 - val_accuracy: 0.7432\nEpoch 155/1000\n65/65 [==============================] - 0s 6ms/step - loss: 0.4757 - accuracy: 0.8538 - val_loss: 1.0314 - val_accuracy: 0.7405\nEpoch 156/1000\n65/65 [==============================] - 1s 8ms/step - loss: 0.4899 - accuracy: 0.8533 - val_loss: 1.0374 - val_accuracy: 0.7459\nEpoch 157/1000\n65/65 [==============================] - 1s 8ms/step - loss: 0.4869 - accuracy: 0.8524 - val_loss: 1.0539 - val_accuracy: 0.7459\nEpoch 158/1000\n65/65 [==============================] - 0s 6ms/step - loss: 0.4838 - accuracy: 0.8465 - val_loss: 1.0557 - val_accuracy: 0.7459\nEpoch 159/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.8504 - val_loss: 1.0484 - val_accuracy: 0.7486\nEpoch 160/1000\n65/65 [==============================] - 0s 5ms/step - loss: 0.5036 - accuracy: 0.8422 - val_loss: 1.0520 - val_accuracy: 0.7432\nEpoch 161/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.8431 - val_loss: 1.0479 - val_accuracy: 0.7459\nEpoch 162/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.8528 - val_loss: 1.0613 - val_accuracy: 0.7405\nEpoch 163/1000\n65/65 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.8499 - val_loss: 1.0600 - val_accuracy: 0.7432\nEpoch 164/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.8456 - val_loss: 1.0572 - val_accuracy: 0.7459\nEpoch 165/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.8562 - val_loss: 1.0552 - val_accuracy: 0.7459\nEpoch 166/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.8524 - val_loss: 1.0564 - val_accuracy: 0.7459\nEpoch 167/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.8528 - val_loss: 1.0509 - val_accuracy: 0.7459\nEpoch 168/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4935 - accuracy: 0.8514 - val_loss: 1.0506 - val_accuracy: 0.7432\nEpoch 169/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.8436 - val_loss: 1.0523 - val_accuracy: 0.7432\nEpoch 170/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.8514 - val_loss: 1.0580 - val_accuracy: 0.7459\nEpoch 171/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.8582 - val_loss: 1.0608 - val_accuracy: 0.7459\nEpoch 172/1000\n65/65 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.8524 - val_loss: 1.0583 - val_accuracy: 0.7432\nEpoch 173/1000\n65/65 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.8606 - val_loss: 1.0588 - val_accuracy: 0.7459\n","output_type":"stream"}]},{"cell_type":"code","source":"# Code to generate the plots of training/validation loss and training/validation accuracy of the model\n\nbest_epoch = np.argmax(history['val_accuracy'])\nplt.figure(figsize=(17,4))\nplt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\nplt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\nplt.title('Categorical Crossentropy')\nplt.legend()\nplt.grid(alpha=.3)\nplt.show()\n\nplt.figure(figsize=(17,4))\nplt.plot(history['accuracy'], label='Training accuracy', alpha=.8, color='#ff7f0e')\nplt.plot(history['val_accuracy'], label='Validation accuracy', alpha=.9, color='#5a9aa5')\nplt.title('Accuracy')\nplt.legend()\nplt.grid(alpha=.3)\nplt.show()\n\nplt.figure(figsize=(18,3))\nplt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\nplt.legend()\nplt.grid(alpha=.3)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-11T20:44:33.255849Z","iopub.execute_input":"2022-12-11T20:44:33.256266Z","iopub.status.idle":"2022-12-11T20:44:33.977514Z","shell.execute_reply.started":"2022-12-11T20:44:33.256234Z","shell.execute_reply":"2022-12-11T20:44:33.976367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model\n\nmodel.save('15_12_second_model')","metadata":{"execution":{"iopub.status.busy":"2022-12-15T21:31:27.177670Z","iopub.execute_input":"2022-12-15T21:31:27.178029Z","iopub.status.idle":"2022-12-15T21:31:28.578521Z","shell.execute_reply.started":"2022-12-15T21:31:27.177996Z","shell.execute_reply":"2022-12-15T21:31:28.577554Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Create a zip of the saved model\n\nimport shutil\nshutil.make_archive(\"15_12_second_model\", 'zip', \"/kaggle/working/15_12_second_model\")","metadata":{"execution":{"iopub.status.busy":"2022-12-15T21:31:29.216832Z","iopub.execute_input":"2022-12-15T21:31:29.217226Z","iopub.status.idle":"2022-12-15T21:31:29.356817Z","shell.execute_reply.started":"2022-12-15T21:31:29.217193Z","shell.execute_reply":"2022-12-15T21:31:29.355781Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/15_12_second_model.zip'"},"metadata":{}}]}]}